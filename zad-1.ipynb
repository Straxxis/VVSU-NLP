{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–∏–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'httpcore' has no attribute 'SyncHTTPTransport'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpymorphy3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MorphAnalyzer\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SnowballStemmer\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogletrans\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Translator\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n\u001b[0;32m      8\u001b[0m nltk\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstopwords\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\googletrans\\__init__.py:6\u001b[0m\n\u001b[0;32m      2\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTranslator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4.0.0-rc.1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogletrans\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Translator\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogletrans\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LANGCODES, LANGUAGES  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\googletrans\\client.py:30\u001b[0m\n\u001b[0;32m     26\u001b[0m EXCLUDES \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mca\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     28\u001b[0m RPC_ID \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMkEWBc\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mTranslator\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"Google Translate ajax API implementation class\u001b[39;49;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;43;03m    You have to create an instance of Translator to use this API\u001b[39;49;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;43;03m    :type raise_exception: boolean\u001b[39;49;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_urls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEFAULT_CLIENT_SERVICE_URLS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEFAULT_USER_AGENT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mraise_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEFAULT_RAISE_EXCEPTION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyping\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttpcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSyncHTTPTransport\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mTimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mhttp2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m                 \u001b[49m\u001b[43muse_fallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\googletrans\\client.py:62\u001b[0m, in \u001b[0;36mTranslator\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTranslator\u001b[39;00m:\n\u001b[0;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Google Translate ajax API implementation class\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03m    You have to create an instance of Translator to use this API\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    :type raise_exception: boolean\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, service_urls\u001b[38;5;241m=\u001b[39mDEFAULT_CLIENT_SERVICE_URLS, user_agent\u001b[38;5;241m=\u001b[39mDEFAULT_USER_AGENT,\n\u001b[0;32m     61\u001b[0m                  raise_exception\u001b[38;5;241m=\u001b[39mDEFAULT_RAISE_EXCEPTION,\n\u001b[1;32m---> 62\u001b[0m                  proxies: typing\u001b[38;5;241m.\u001b[39mDict[\u001b[38;5;28mstr\u001b[39m, \u001b[43mhttpcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSyncHTTPTransport\u001b[49m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     63\u001b[0m                  timeout: Timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     64\u001b[0m                  http2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     65\u001b[0m                  use_fallback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m httpx\u001b[38;5;241m.\u001b[39mClient(http2\u001b[38;5;241m=\u001b[39mhttp2)\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m proxies \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# pragma: nocover\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'httpcore' has no attribute 'SyncHTTPTransport'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy3 import MorphAnalyzer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from googletrans import Translator\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∫–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤ –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Translator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m stemmer \u001b[38;5;241m=\u001b[39m SnowballStemmer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrussian\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m translator \u001b[38;5;241m=\u001b[39m \u001b[43mTranslator\u001b[49m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Translator' is not defined"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('russian'))\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –∏ —Å—Ç–µ–º–º–µ—Ä–∞\n",
    "morph = MorphAnalyzer()\n",
    "stemmer = SnowballStemmer(\"russian\")\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞\n",
    "translator = Translator()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "—Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lemmatize_word(word):\n",
    "    return morph.parse(word)[0].normal_form\n",
    "\n",
    "def stem_word(word):\n",
    "    return stemmer.stem(word)\n",
    "\n",
    "def process_text(text):\n",
    "    words = text.split()\n",
    "    # –£–±–∏—Ä–∞–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    lemmatized_words = [lemmatize_word(word) for word in filtered_words]\n",
    "    stemmed_words = [stem_word(word) for word in filtered_words]\n",
    "    \n",
    "    return lemmatized_words, stemmed_words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " –§—É–Ω–∫—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞ —Ç–µ–∫—Å—Ç–∞ —Å —Ä—É—Å—Å–∫–æ–≥–æ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π, –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_to_english(text):\n",
    "    translation = translator.translate(text, src='ru', dest='en')\n",
    "    return translation.text\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return list(text)\n",
    "\n",
    "def vectorize_text(text):\n",
    "    # –ü—Ä–∏–≤–æ–¥–∏–º —Ç–µ–∫—Å—Ç –∫ ASCII (–æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å–∏–º–≤–æ–ª—ã —Å –∫–æ–¥–∞–º–∏ < 128)\n",
    "    ascii_text = ''.join([char if ord(char) < 128 else ' ' for char in text])\n",
    "    \n",
    "    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–∞–∂–¥—ã–π —Å–∏–º–≤–æ–ª –≤ –µ–≥–æ ASCII –∫–æ–¥\n",
    "    ascii_codes = [ord(char) for char in ascii_text]\n",
    "    \n",
    "    return ascii_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç\n",
    "text = \"–£–º–Ω—ã–π –Ω–∞ –≥–æ—Ä—É –Ω–µ –ø–æ–π–¥–µ—Ç, —É–º–Ω—ã–π –≥–æ—Ä—É –æ–±–æ–π–¥–µ—Ç. –ù–æ —É–º–Ω—ã–π –ø–æ–π–¥–µ—Ç –Ω–∞ –≥–æ—Ä—É, –µ—Å–ª–∏ —Ç–∞–º –¥–µ–≤—É—à–∫–∏ –∂–∏–≤—É—Ç.\"\n",
    "\n",
    "# –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è –∏ —Å—Ç–µ–º–º–∏–Ω–≥\n",
    "lemmatized_text, stemmed_text = process_text(text)\n",
    "\n",
    "# –ü–µ—Ä–µ–≤–æ–¥ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π\n",
    "translated_lemmatized_text = translate_to_english(' '.join(lemmatized_text))\n",
    "translated_stemmed_text = translate_to_english(' '.join(stemmed_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è —Ä—É—Å—Å–∫–∞—è\n",
    "ru_tokenized_lemmatized_text = tokenize_text(' '.join(lemmatized_text))\n",
    "ru_tokenized_stemmed_text = tokenize_text(' '.join(stemmed_text))\n",
    "\n",
    "# –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∞–Ω–≥–ª–∏–π—Å–∫–∞—è\n",
    "tokenized_lemmatized_text = tokenize_text(translated_lemmatized_text)\n",
    "tokenized_stemmed_text = tokenize_text(translated_stemmed_text)\n",
    "vectorized_lemmatized_text = vectorize_text(translated_lemmatized_text)\n",
    "vectorized_stemmed_text = vectorize_text(translated_stemmed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è: ['—Å–∞—à–∞', '–∏–¥—Ç–∏', '—à–æ—Å—Å–µ', '—Å–æ—Å–∞—Ç—å', '—Å—É—à–∫–∞']\n",
      "–°—Ç–µ–º–º–∏–Ω–≥: ['—Å–∞—à', '—à–ª–∞', '—à–æ—Å—Å', '—Å–æ—Å–∞', '—Å—É—à–∫']\n",
      "----------------------------------------\n",
      "\n",
      "üîπ –†—É—Å—Å–∫–∞—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è:\n",
      "–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è: ['—Å', '–∞', '—à', '–∞', ' ', '–∏', '–¥', '—Ç', '–∏', ' ', '—à', '–æ', '—Å', '—Å', '–µ', ' ', '—Å', '–æ', '—Å', '–∞', '—Ç', '—å', ' ', '—Å', '—É', '—à', '–∫', '–∞']\n",
      "–°—Ç–µ–º–º–∏–Ω–≥: ['—Å', '–∞', '—à', ' ', '—à', '–ª', '–∞', ' ', '—à', '–æ', '—Å', '—Å', ' ', '—Å', '–æ', '—Å', '–∞', ' ', '—Å', '—É', '—à', '–∫']\n",
      "\n",
      "üîπ –ê–Ω–≥–ª–∏–π—Å–∫–∞—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è:\n",
      "–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è: ['S', 'a', 's', 'h', 'a', ' ', 'g', 'o', ' ', 'h', 'i', 'g', 'h', 'w', 'a', 'y', ' ', 't', 'o', ' ', 's', 'u', 'c', 'k', ' ', 'd', 'r', 'y', 'i', 'n', 'g']\n",
      "–°—Ç–µ–º–º–∏–Ω–≥: ['S', 'a', 's', 'h', ' ', 'w', 'a', 'l', 'k', 'e', 'd', ' ', 'h', 'i', 'g', 'h', 'w', 'a', 'y', ' ', 's', 'u', 'z', 'a', ' ', 's', 'u', 's', 'h', 'k']\n",
      "\n",
      "üîπ –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è:\n",
      "–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è: [83, 97, 115, 104, 97, 32, 103, 111, 32, 104, 105, 103, 104, 119, 97, 121, 32, 116, 111, 32, 115, 117, 99, 107, 32, 100, 114, 121, 105, 110, 103] ... (–≤—Å–µ–≥–æ 31 —ç–ª–µ–º–µ–Ω—Ç–æ–≤)\n",
      "–°—Ç–µ–º–º–∏–Ω–≥: [83, 97, 115, 104, 32, 119, 97, 108, 107, 101, 100, 32, 104, 105, 103, 104, 119, 97, 121, 32, 115, 117, 122, 97, 32, 115, 117, 115, 104, 107] ... (–≤—Å–µ–≥–æ 30 —ç–ª–µ–º–µ–Ω—Ç–æ–≤)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"-\" * 40)\n",
    "print(f\"–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è: {lemmatized_text}\")\n",
    "print(f\"–°—Ç–µ–º–º–∏–Ω–≥: {stemmed_text}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "print(\"\\nüîπ –†—É—Å—Å–∫–∞—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è:\")\n",
    "print(\"–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è:\", ru_tokenized_lemmatized_text)\n",
    "print(\"–°—Ç–µ–º–º–∏–Ω–≥:\", ru_tokenized_stemmed_text)\n",
    "\n",
    "print(\"\\nüîπ –ê–Ω–≥–ª–∏–π—Å–∫–∞—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è:\")\n",
    "print(\"–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è:\", tokenized_lemmatized_text)\n",
    "print(\"–°—Ç–µ–º–º–∏–Ω–≥:\", tokenized_stemmed_text)\n",
    "\n",
    "print(\"\\nüîπ –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è:\")\n",
    "print(\"–õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏—è:\", vectorized_lemmatized_text, \"...\", f\"(–≤—Å–µ–≥–æ {len(vectorized_lemmatized_text)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤)\")\n",
    "print(\"–°—Ç–µ–º–º–∏–Ω–≥:\", vectorized_stemmed_text, \"...\", f\"(–≤—Å–µ–≥–æ {len(vectorized_stemmed_text)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤)\")\n",
    "print(\"-\" * 40)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
